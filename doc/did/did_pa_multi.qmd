---
title: "DiD for Panel Data over Multiple Periods"

jupyter: python3
---

```{python}
#| echo: false

import numpy as np
import pandas as pd
from itables import init_notebook_mode
import os
import sys

doc_dir = os.path.abspath(os.path.join(os.getcwd(), ".."))
if doc_dir not in sys.path:
    sys.path.append(doc_dir)

from utils.style_tables import generate_and_show_styled_table

init_notebook_mode(all_interactive=True)
```

## Coverage

The simulations are based on the  the [make_did_CS2021](https://docs.doubleml.org/stable/api/generated/doubleml.did.datasets.make_did_CS2021.html)-DGP with $2000$ observations. Learners are both set to either boosting or a linear (logistic) model. Due to time constraints we only consider the following DGPs:

 - Type 1: Linear outcome model and treatment assignment
 - Type 4: Nonlinear outcome model and treatment assignment
 - Type 6: Randomized treatment assignment and nonlinear outcome model

The non-uniform results (coverage, ci length and bias) refer to averaged values over all $ATTs$ (point-wise confidende intervals).

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/did/did_pa_multi_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df = pd.read_csv("../../results/did/did_pa_multi_detailed.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "DGP", "In-sample-norm.", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


### Experimental Score

The results are only valid for the DGP 6, as the experimental score assumes a randomized treatment assignment.

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.95, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.9, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

## Aggregated Effects

These simulations test different types of aggregation, as described in [DiD User Guide](https://docs.doubleml.org/stable/guide/models.html#difference-in-differences-models-did).

The non-uniform results (coverage, ci length and bias) refer to averaged values over all $ATTs$ (point-wise confidende intervals).

### Group Effects

```{python}
#| echo: false

# set up data
df_group = pd.read_csv("../../results/did/did_pa_multi_group.csv", index_col=None)

assert df_group["repetition"].nunique() == 1
n_rep_group = df_group["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "DGP", "In-sample-norm.", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_group,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_group,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

#### Experimental Score

The results are only valid for the DGP 6, as the experimental score assumes a randomized treatment assignment.

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group,
    filters={"level": 0.95, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_group,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group,
    filters={"level": 0.9, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_group,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

### Time Effects

```{python}
#| echo: false

# set up data
df_time = pd.read_csv("../../results/did/did_pa_multi_time.csv", index_col=None)

assert df_time["repetition"].nunique() == 1
n_rep_time = df_time["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "DGP", "In-sample-norm.", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_time,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_time,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

#### Experimental Score

The results are only valid for the DGP 6, as the experimental score assumes a randomized treatment assignment.

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time,
    filters={"level": 0.95, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_time,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time,
    filters={"level": 0.9, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_time,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

### Event Study Aggregation

```{python}
#| echo: false

# set up data
df_es = pd.read_csv("../../results/did/did_pa_multi_eventstudy.csv", index_col=None)

assert df_es["repetition"].nunique() == 1
n_rep_es = df_es["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "DGP", "In-sample-norm.", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_es,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep_es,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

#### Experimental Score

The results are only valid for the DGP 6, as the experimental score assumes a randomized treatment assignment.


```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es,
    filters={"level": 0.95, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_es,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es,
    filters={"level": 0.9, "Score": "experimental"},
    display_cols=display_columns,
    n_rep=n_rep_es,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


## Tuning

The simulations are based on the  the [make_did_CS2021](https://docs.doubleml.org/stable/api/generated/doubleml.did.datasets.make_did_CS2021.html)-DGP with $2000$ observations. Due to time constraints we only consider one learner, use in-sample normalization and the following DGPs:

 - Type 1: Linear outcome model and treatment assignment
 - Type 2: Nonlinear outcome model and linear treatment assignment
 - Type 3: Linear outcome model and nonlinear treatment assignment
 - Type 4: Nonlinear outcome model and treatment assignment

The non-uniform results (coverage, ci length and bias) refer to averaged values over all $ATTs$ (point-wise confidende intervals). This is only an example as the untuned version just relies on the default configuration.

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/did/did_pa_multi_tune_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df = pd.read_csv("../../results/did/did_pa_multi_tune_detailed.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "DGP", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns,
    n_rep=n_rep,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

## Tuning Aggregated Effects

These simulations test different types of aggregation, as described in [DiD User Guide](https://docs.doubleml.org/stable/guide/models.html#difference-in-differences-models-did).

As before, we only consider one learner, use in-sample normalization and the following DGPs:

 - Type 1: Linear outcome model and treatment assignment
 - Type 2: Nonlinear outcome model and linear treatment assignment
 - Type 3: Linear outcome model and nonlinear treatment assignment
 - Type 4: Nonlinear outcome model and treatment assignment

The non-uniform results (coverage, ci length and bias) refer to averaged values over all $ATTs$ (point-wise confidende intervals). This is only an example as the untuned version just relies on the default configuration.

### Group Effects

```{python}
#| echo: false

# set up data
df_group_tune = pd.read_csv("../../results/did/did_pa_multi_tune_group.csv", index_col=None)

assert df_group_tune["repetition"].nunique() == 1
n_rep_group_tune = df_group_tune["repetition"].unique()[0]

display_columns_tune = ["Learner g", "Learner m", "DGP", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group_tune,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_group_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_group_tune,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_group_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


### Time Effects

```{python}
#| echo: false

# set up data
df_time_tune = pd.read_csv("../../results/did/did_pa_multi_tune_time.csv", index_col=None)

assert df_time_tune["repetition"].nunique() == 1
n_rep_time_tune = df_time_tune["repetition"].unique()[0]

display_columns_tune = ["Learner g", "Learner m", "DGP", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time_tune,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_time_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_time_tune,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_time_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

### Event Study Aggregation

```{python}
#| echo: false

# set up data
df_es_tune = pd.read_csv("../../results/did/did_pa_multi_tune_eventstudy.csv", index_col=None)

assert df_es_tune["repetition"].nunique() == 1
n_rep_es_tune = df_es_tune["repetition"].unique()[0]

display_columns_tune = ["Learner g", "Learner m", "DGP", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

#### Observational Score

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es_tune,
    filters={"level": 0.95, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_es_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

```{python}
#| echo: false
generate_and_show_styled_table(
    main_df=df_es_tune,
    filters={"level": 0.9, "Score": "observational"},
    display_cols=display_columns_tune,
    n_rep=n_rep_es_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```
