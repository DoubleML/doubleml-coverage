---
title: "APO Models"

jupyter: python3
---

```{python}
#| echo: false

import numpy as np
import pandas as pd
from itables import init_notebook_mode
import os
import sys

doc_dir = os.path.abspath(os.path.join(os.getcwd(), ".."))
if doc_dir not in sys.path:
    sys.path.append(doc_dir)

from utils.style_tables import generate_and_show_styled_table

init_notebook_mode(all_interactive=True)
```

## Coverage

### APO Pointwise Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/datasets.html#dataset-generators)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/apo_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df_apo = pd.read_csv("../../results/irm/apo_coverage.csv", index_col=None)

assert df_apo["repetition"].nunique() == 1
n_rep_apo = df_apo["repetition"].unique()[0]

display_columns_apo = ["Learner g", "Learner m", "Treatment Level", "Bias", "CI Length", "Coverage"]
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apo,
    filters={"level": 0.95},
    display_cols=display_columns_apo,
    n_rep=n_rep_apo,
    level_col="level",
    coverage_highlight_cols=["Coverage"]
)
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apo,
    filters={"level": 0.9},
    display_cols=display_columns_apo,
    n_rep=n_rep_apo,
    level_col="level",
    coverage_highlight_cols=["Coverage"]
)
```


### APOS Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/datasets.html#dataset-generators)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

The non-uniform results (coverage, ci length and bias) refer to averaged values over all levels (point-wise confidende intervals).

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/apos_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df_apos = pd.read_csv("../../results/irm/apos_coverage.csv", index_col=None)

assert df_apos["repetition"].nunique() == 1
n_rep_apos = df_apos["repetition"].unique()[0]

display_columns_apos = ["Learner g", "Learner m", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apos,
    filters={"level": 0.95},
    display_cols=display_columns_apos,
    n_rep=n_rep_apos,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apos,
    filters={"level": 0.9},
    display_cols=display_columns_apos,
    n_rep=n_rep_apos,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```

### Causal Contrast Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/datasets.html#dataset-generators)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

The non-uniform results (coverage, ci length and bias) refer to averaged values over all levels (point-wise confidende intervals).

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/apos_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df_contrast = pd.read_csv("../../results/irm/apos_causal_contrast.csv", index_col=None)

assert df_contrast["repetition"].nunique() == 1
n_rep_contrast = df_contrast["repetition"].unique()[0]

display_columns_contrast = ["Learner g", "Learner m", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_contrast,
    filters={"level": 0.95},
    display_cols=display_columns_contrast,
    n_rep=n_rep_contrast,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_contrast,
    filters={"level": 0.9},
    display_cols=display_columns_contrast,
    n_rep=n_rep_contrast,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


## Tuning

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/datasets.html#dataset-generators)-DGP with $500$ observations. This is only an example as the untuned version just relies on the default configuration.

### APOS Coverage

The non-uniform results (coverage, ci length and bias) refer to averaged values over all levels (point-wise confidende intervals). The same holds for the loss values which are averaged over all treatment levels.

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/apos_tune_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df_apos_tune = pd.read_csv("../../results/irm/apos_tune_coverage.csv", index_col=None)

assert df_apos_tune["repetition"].nunique() == 1
n_rep_apos_tune = df_apos_tune["repetition"].unique()[0]

display_columns_apos_tune = ["Learner g", "Learner m", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apos_tune,
    filters={"level": 0.95},
    display_cols=display_columns_apos_tune,
    n_rep=n_rep_apos_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_apos_tune,
    filters={"level": 0.9},
    display_cols=display_columns_apos_tune,
    n_rep=n_rep_apos_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


### Causal Contrast Coverage

The non-uniform results (coverage, ci length and bias) refer to averaged values over all quantiles (point-wise confidende intervals). The same holds for the loss values which are averaged over all treatment levels.


::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/apos_tune_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data
df_contrast_tune = pd.read_csv("../../results/irm/apos_tune_causal_contrast.csv", index_col=None)

assert df_contrast_tune["repetition"].nunique() == 1
n_rep_contrast_tune = df_contrast_tune["repetition"].unique()[0]

display_columns_contrast_tune = ["Learner g", "Learner m", "Tuned", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage", "Loss g_control", "Loss g_treated", "Loss m"]
```

```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_contrast_tune,
    filters={"level": 0.95},
    display_cols=display_columns_contrast_tune,
    n_rep=n_rep_contrast_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```


```{python}
#| echo: false

generate_and_show_styled_table(
    main_df=df_contrast_tune,
    filters={"level": 0.9},
    display_cols=display_columns_contrast_tune,
    n_rep=n_rep_contrast_tune,
    level_col="level",
    coverage_highlight_cols=["Coverage", "Uniform Coverage"]
)
```