---
title: "APO Models"

jupyter: python3
---

```{python}
#| echo: false

import numpy as np
import pandas as pd
from itables import init_notebook_mode, show, options

init_notebook_mode(all_interactive=True)

def highlight_range(s, level=0.95, dist=0.05, props=''):
    color_grid = np.where((s >= level-dist) &
                          (s <= level+dist), props, '')
    return color_grid


def color_coverage(df, level):
    # color coverage column order is important
    styled_df = df.apply(
        highlight_range,
        level=level,
        dist=1.0,
        props='color:black;background-color:red',
        subset=["Coverage"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.1,
        props='color:black;background-color:yellow',
        subset=["Coverage"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.05,
        props='color:white;background-color:darkgreen',
        subset=["Coverage"])

    # set all coverage values to bold
    styled_df = styled_df.set_properties(
        **{'font-weight': 'bold'},
        subset=["Coverage"])
    return styled_df


def make_pretty(df, level, n_rep):
    styled_df = df.style.hide(axis="index")
    # Format only float columns
    float_cols = df.select_dtypes(include=['float']).columns
    styled_df = styled_df.format({col: "{:.3f}" for col in float_cols})

    # color coverage column order is important
    styled_df = color_coverage(styled_df, level)
    caption = f"Coverage for {level*100}%-Confidence Interval over {n_rep} Repetitions"

    return show(styled_df, caption=caption)
```

## APO Pointwise Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/api.html#datasets-module)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/irm_apo_coverage_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data and rename columns
df = pd.read_csv("../../results/irm/irm_apo_coverage_apo.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "Treatment Level", "Bias", "CI Length", "Coverage"]
```


```{python}
#| echo: false

level = 0.95
df_ate_95 = df[df['level'] == level][display_columns]
make_pretty(df_ate_95, level, n_rep)
```


```{python}
#| echo: false

level = 0.9
df_ate_9 = df[df['level'] == level][display_columns]
make_pretty(df_ate_9, level, n_rep)
```


## APOS Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/api.html#datasets-module)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

The non-uniform results (coverage, ci length and bias) refer to averaged values over all quantiles (point-wise confidende intervals). 

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/irm_apo_coverage_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

def highlight_range(s, level=0.95, dist=0.05, props=''):
    color_grid = np.where((s >= level-dist) &
                          (s <= level+dist), props, '')
    return color_grid


def color_coverage(df, level):
    # color coverage column order is important
    styled_df = df.apply(
        highlight_range,
        level=level,
        dist=1.0,
        props='color:black;background-color:red',
        subset=["Coverage", "Uniform Coverage"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.1,
        props='color:black;background-color:yellow',
        subset=["Coverage", "Uniform Coverage"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.05,
        props='color:white;background-color:darkgreen',
        subset=["Coverage", "Uniform Coverage"])

    # set all coverage values to bold
    styled_df = styled_df.set_properties(
        **{'font-weight': 'bold'},
        subset=["Coverage", "Uniform Coverage"])
    return styled_df


def make_pretty(df, level, n_rep):
    styled_df = df.style.hide(axis="index")
    # Format only float columns
    float_cols = df.select_dtypes(include=['float']).columns
    styled_df = styled_df.format({col: "{:.3f}" for col in float_cols})

    # color coverage column order is important
    styled_df = color_coverage(styled_df, level)
    caption = f"Coverage for {level*100}%-Confidence Interval over {n_rep} Repetitions"

    return show(styled_df, caption=caption)
```

```{python}
#| echo: false

# set up data and rename columns
df = pd.read_csv("../../results/irm/irm_apo_coverage_apos.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

```{python}
#| echo: false

level = 0.95
df_ate_95 = df[df['level'] == level][display_columns]
make_pretty(df_ate_95, level, n_rep)
```


```{python}
#| echo: false

level = 0.9
df_ate_9 = df[df['level'] == level][display_columns]
make_pretty(df_ate_9, level, n_rep)
```

## Causal Contrast Coverage

The simulations are based on the  the [make_irm_data_discrete_treatments](https://docs.doubleml.org/stable/api/api.html#datasets-module)-DGP with $500$ observations. Due to the linearity of the DGP, Lasso and Logit Regression are nearly optimal choices for the nuisance estimation.

The non-uniform results (coverage, ci length and bias) refer to averaged values over all quantiles (point-wise confidende intervals). 

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/irm_apo_coverage_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data and rename columns
df = pd.read_csv("../../results/irm/irm_apo_coverage_apos_contrast.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = ["Learner g", "Learner m", "Bias", "CI Length", "Coverage", "Uniform CI Length", "Uniform Coverage"]
```

```{python}
#| echo: false

level = 0.95
df_ate_95 = df[df['level'] == level][display_columns]
make_pretty(df_ate_95, level, n_rep)
```


```{python}
#| echo: false

level = 0.9
df_ate_9 = df[df['level'] == level][display_columns]
make_pretty(df_ate_9, level, n_rep)
```


## Causal Contrast Sensitivity

The simulations are based on the  the ADD-DGP with $10,000$ observations. As the DGP is nonlinear, we will only use corresponding learners. Since the DGP includes an unobserved confounder, we would expect a bias in the ATE estimates, leading to low coverage of the true parameter.

The confounding is set such that both sensitivity parameters are approximately $cf_y=cf_d=0.1$, such that the robustness value $RV$ should be approximately $10\%$.
Further, the corresponding confidence intervals are one-sided (since the direction of the bias is unkown), such that only one side should approximate the corresponding coverage level (here only the lower coverage is relevant since the bias is positive). Remark that for the coverage level the value of $\rho$ has to be correctly specified, such that the coverage level will be generally (significantly) larger than the nominal level under the conservative choice of $|\rho|=1$.

```{python}
#| echo: false

import numpy as np
import pandas as pd
from itables import init_notebook_mode, show, options

init_notebook_mode(all_interactive=True)

def highlight_range(s, level=0.95, dist=0.05, props=''):
    color_grid = np.where((s >= level-dist) &
                          (s <= level+dist), props, '')
    return color_grid


def color_coverage(df, level):
    # color coverage column order is important
    styled_df = df.apply(
        highlight_range,
        level=level,
        dist=1.0,
        props='color:black;background-color:red',
        subset=["Coverage", "Coverage (Lower)"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.1,
        props='color:black;background-color:yellow',
        subset=["Coverage", "Coverage (Lower)"])
    styled_df = styled_df.apply(
        highlight_range,
        level=level,
        dist=0.05,
        props='color:white;background-color:darkgreen',
        subset=["Coverage", "Coverage (Lower)"])

    # set all coverage values to bold
    styled_df = styled_df.set_properties(
        **{'font-weight': 'bold'},
        subset=["Coverage", "Coverage (Lower)"])
    return styled_df


def make_pretty(df, level, n_rep):
    styled_df = df.style.hide(axis="index")
    # Format only float columns
    float_cols = df.select_dtypes(include=['float']).columns
    styled_df = styled_df.format({col: "{:.3f}" for col in float_cols})

    # color coverage column order is important
    styled_df = color_coverage(styled_df, level)
    caption = f"Coverage for {level*100}%-Confidence Interval over {n_rep} Repetitions"

    return show(styled_df, caption=caption)
```

### ATE

::: {.callout-note title="Metadata"  collapse="true"}

```{python}
#| echo: false
metadata_file = '../../results/irm/irm_apo_sensitivity_metadata.csv'
metadata_df = pd.read_csv(metadata_file)
print(metadata_df.T.to_string(header=False))
```

:::

```{python}
#| echo: false

# set up data and rename columns
df = pd.read_csv("../../results/irm/irm_apo_sensitivity.csv", index_col=None)

assert df["repetition"].nunique() == 1
n_rep = df["repetition"].unique()[0]

display_columns = [
    "Learner g", "Learner m", "Bias", "Bias (Lower)", "Bias (Upper)", "Coverage", "Coverage (Lower)", "Coverage (Upper)", "RV", "RVa"]
```

```{python}
#| echo: false
level = 0.95

df_ate_95 = df[(df['level'] == level)][display_columns]
df_ate_95.rename(columns={"Learner g": "Learner l"}, inplace=True)
make_pretty(df_ate_95, level, n_rep)
```

```{python}
#| echo: false
level = 0.9

df_ate_9 = df[(df['level'] == level)][display_columns]
df_ate_9.rename(columns={"Learner g": "Learner l"}, inplace=True)
make_pretty(df_ate_9, level, n_rep)
```

